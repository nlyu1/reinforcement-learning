def:finiteMDP
def:policyTrajectory
def:vqfunctions
prp:vqRelations
def:consistencyOp
def:unlabeled-div-1
thm:optimalVQRelation
def:optimalityOp
def:greedyPolicy
thm:greedyPolicyOptimal
def:unlabeled-div-3
thm:contraction
lem:pairAbsDiff
def:finiteVI
prp:infVI
thm:greedyPolicyValueBound
def:infPolicyIter
thm:infPolicyIterProof
def:polEvalCriteria
def:mcPolEval
def:unlabeled-div-8
exm:unlabeled-div-9
thm:batchMCTDBehavior
def:policyStatus
def:onlineStatus
def:MCPI
def:unlabeled-div-10
def:TDPI
def:qLearning
prp:qVariants
def:unlabeled-div-11
thm:PG
thm:pgBaseline
def:advantage
cor:lowvarPG
def:unlabeled-div-12
def:pgMC
def:gae
thm:PDL
def:pgSurrogate
thm:relPerfBound
cor:unlabeled-div-14
def:surrogatePG
def:ppoClip
def:vTraceAlgo
def:imlSetup
def:demoiml
def:unlabeled-div-15
thm:rewardShapingTheorem
def:linFeatureAssumption
prp:featureMatchingLearning
def:classicalIRL
def:maxEntPrinciple
thm:maxEntReduction
lem:unlabeled-div-16
def:maxEntIRLAlg
def:bradleyTerry
def:unlabeled-div-17
def:hfModel
def:rlhf
def:dpoAlg
def:multiArmBandit
def:unlabeled-div-18
thm:regretLowerBound
thm:hoeffding
def:ucb
thm:ucbRegret
def:probMatching
def:thompsonSamp
mdp
sampMDP
polMethods
iRL
rlLLMs
